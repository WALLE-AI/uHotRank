"""
åŸºäºå†…å®¹åˆ†æçš„æœç´¢ç¤ºä¾‹
"""
from backend.db import ElasticsearchClient, ArticleRepository


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("åŸºäºå†…å®¹åˆ†æçš„æœç´¢")
    print("=" * 80)
    print()
    
    # è¿æ¥ ES
    try:
        es_client = ElasticsearchClient()
        repo = ArticleRepository(es_client, index_name="tophub_articles")
        print("âœ… è¿æ¥æˆåŠŸ\n")
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")
        return
    
    try:
        # 1. ç»Ÿè®¡ä¿¡æ¯
        print("ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print("-" * 80)
        total = repo.count()
        analyzed = repo.count(query={"term": {"content_analysis.analysis_success": True}})
        print(f"æ€»æ–‡æ¡£æ•°: {total}")
        print(f"å·²åˆ†ææ–‡æ¡£: {analyzed}")
        print(f"åˆ†æç‡: {analyzed/total*100:.1f}%" if total > 0 else "0%")
        print()
        
        # 2. çƒ­é—¨å…³é”®è¯
        print("ğŸ”‘ çƒ­é—¨å…³é”®è¯ (Top 20):")
        print("-" * 80)
        top_keywords = repo.get_keyword_statistics(top_n=20)
        for i, item in enumerate(top_keywords, 1):
            print(f"{i:2d}. {item['keyword']:<20} {item['count']:>3} æ¬¡")
        print()
        
        # 3. çƒ­é—¨ä¸»é¢˜
        print("ğŸ“š çƒ­é—¨ä¸»é¢˜ (Top 10):")
        print("-" * 80)
        top_topics = repo.get_topic_statistics(top_n=10)
        for i, item in enumerate(top_topics, 1):
            print(f"{i:2d}. {item['topic']:<30} {item['count']:>3} æ¬¡")
        print()
        
        # 4. åˆ†ç±»ç»Ÿè®¡
        print("ğŸ“‚ åˆ†ç±»ç»Ÿè®¡:")
        print("-" * 80)
        categories = repo.get_category_statistics()
        for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
            print(f"  {category:<20} {count:>3} ç¯‡")
        print()
        
        # 5. æƒ…æ„Ÿç»Ÿè®¡
        print("ğŸ˜Š æƒ…æ„Ÿç»Ÿè®¡:")
        print("-" * 80)
        sentiments = repo.get_sentiment_statistics()
        sentiment_names = {
            "positive": "ç§¯æ",
            "neutral": "ä¸­æ€§",
            "negative": "æ¶ˆæ"
        }
        for sentiment, count in sentiments.items():
            name = sentiment_names.get(sentiment, sentiment)
            print(f"  {name:<10} {count:>3} ç¯‡")
        print()
        
        # 6. é€šè¿‡å…³é”®è¯æœç´¢
        print("ğŸ” æœç´¢ç¤ºä¾‹ 1: é€šè¿‡å…³é”®è¯æœç´¢")
        print("-" * 80)
        keyword = input("è¯·è¾“å…¥å…³é”®è¯ (é»˜è®¤: AI): ").strip() or "AI"
        
        results = repo.search_by_keywords([keyword], size=5)
        print(f"\næ‰¾åˆ° {len(results)} æ¡ç»“æœ:\n")
        
        for i, doc in enumerate(results, 1):
            analysis = doc.get('content_analysis', {})
            print(f"{i}. {doc.get('title', 'N/A')}")
            print(f"   åˆ†ç±»: {analysis.get('category', 'N/A')}")
            print(f"   å…³é”®è¯: {', '.join(analysis.get('keywords', [])[:5])}")
            print(f"   æƒ…æ„Ÿ: {analysis.get('sentiment', 'N/A')}")
            print()
        
        # 7. é€šè¿‡ä¸»é¢˜æœç´¢
        print("ğŸ” æœç´¢ç¤ºä¾‹ 2: é€šè¿‡ä¸»é¢˜æœç´¢")
        print("-" * 80)
        
        if top_topics:
            topic = top_topics[0]['topic']
            print(f"æœç´¢ä¸»é¢˜: {topic}\n")
            
            results = repo.search_by_topic(topic, size=5)
            print(f"æ‰¾åˆ° {len(results)} æ¡ç»“æœ:\n")
            
            for i, doc in enumerate(results, 1):
                analysis = doc.get('content_analysis', {})
                print(f"{i}. {doc.get('title', 'N/A')}")
                print(f"   ä¸»é¢˜: {', '.join(analysis.get('topics', []))}")
                print()
        
        # 8. é€šè¿‡åˆ†ç±»æœç´¢
        print("ğŸ” æœç´¢ç¤ºä¾‹ 3: é€šè¿‡åˆ†ç±»æœç´¢")
        print("-" * 80)
        
        if categories:
            category = list(categories.keys())[0]
            print(f"æœç´¢åˆ†ç±»: {category}\n")
            
            results = repo.search_by_category(category, size=5)
            print(f"æ‰¾åˆ° {len(results)} æ¡ç»“æœ:\n")
            
            for i, doc in enumerate(results, 1):
                analysis = doc.get('content_analysis', {})
                print(f"{i}. {doc.get('title', 'N/A')}")
                print(f"   æ‘˜è¦: {analysis.get('summary', 'N/A')[:100]}...")
                print()
        
        # 9. é€šè¿‡æƒ…æ„Ÿæœç´¢
        print("ğŸ” æœç´¢ç¤ºä¾‹ 4: é€šè¿‡æƒ…æ„Ÿæœç´¢")
        print("-" * 80)
        sentiment = input("è¯·è¾“å…¥æƒ…æ„Ÿ (positive/neutral/negativeï¼Œé»˜è®¤: positive): ").strip() or "positive"
        
        results = repo.search_by_sentiment(sentiment, size=5)
        print(f"\næ‰¾åˆ° {len(results)} æ¡ç»“æœ:\n")
        
        for i, doc in enumerate(results, 1):
            analysis = doc.get('content_analysis', {})
            print(f"{i}. {doc.get('title', 'N/A')}")
            print(f"   æƒ…æ„Ÿ: {analysis.get('sentiment', 'N/A')}")
            print(f"   æ‘˜è¦: {analysis.get('summary', 'N/A')[:100]}...")
            print()
        
    except Exception as e:
        print(f"âŒ æœç´¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        es_client.close()
        print("=" * 80)
        print("âœ… è¿æ¥å·²å…³é—­")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
